We restrict the model to working days and people that arrive at work between $6\unit{a.m.}$ and $11\unit{a.m.}$ and return home before $11\unit{p.m}$. We also omit lunch activities and business trips. Car ownership, work location, working time and whether people have fixed or flexible working schedules is exogenous in the current implementation. Escort trips of children to or from school/daycare are mandatory for individuals that do the trip on the survey day, and drop off/pick up location is exogenous. 

We currently do not consider any mixed modes, or mode chains, such as taking the bike to the train station. This would definitely be possible conceptually, but would further increase the computation time and has therefore not been included at this stage. Car is only a possible choice if the individual has a car available at home. Further, if a car is used for a trip away from home, all consecutive trips on the same tour must be done using car. This is controlled through the car-dummy $\delta_{car}$. Certainly it happens that individuals use a car for only some trips in a tour. They might leave their car at work and pick it up the next day or leave it for another family member. To correctly include the possibility to leave a car at any location, another state variable would be needed that remembered the location where the car was parked and the state space would become 1000-times larger. Since that kind of behaviour is quite uncommon, we think this restriction on car usage is reasonable. %How is this done in other papers?

Below we will first describe the state space and choice set, and then how time-space constraints can be expressed in terms of restrictions on either the state space or on a state specific choice set.



\subsection{Specification}
\subsubsection{State and action space}
\input{text/caseStudy/StateAndActions.tex}
\subsubsection{Time-space constraint}
\input{text/caseStudy/TimeSpaceConstraints.tex}
\subsubsection{One-stage utility functions}
\input{text/caseStudy/Utility.tex}
\subsection{Estimation}
The standard method for estimating dynamic discrete choice models is the Nested Fixed Point Method (NFXP) \citep{RustML88}. This involves first calculating $\eutil$ and its gradients in each state of the network and then directly use \eqref{eq:pPath0} for estimation. Although possible to apply on the proposed model, the method would be extremely time consuming given the discussion on computation time in Section \ref{seq:computationTime}. If estimation would rely on calculating the value function and gradient of the value function in each state in each iteration, the computation time would likely be $0.4\cdot N_{\text{variables}} \cdot t$ per observation per iteration (as the gradient must be calculated for each variable, requiring at least the additional sum of the gradient of $u + EV$ for each variable). With $10\units{s/observation}$ to calculate $\eutil$, $70$ variables, $3\zdel 300$ observations and $100$ iterations before convergence, this would require $10 \cdot 0.4 \cdot  70 \cdot 3\zdel 300 \cdot 100 \units{s} \approx 1\zdel 000 \units{days}$ to estimate using a single core. 

Methods used to speed up estimation of dynamic discrete choice models, e.g., the method proposed in \citet{aguirregabiria2002swapping}, reduces the burden of value iterations when calculating the value function. As no iteration is needed to evaluate the value function in this model, this would likely not help. Some approximative method is therefore needed.

Each individual is considering all possible locations for each new action. Locations are therefore both state variables and alternative actions so the computation time increases quadratically with the number of locations. Restricting the choice set of locations for individuals is therefore extremely tempting, but combining an activity scheduling model with a location choice set model in a consistent way seems extremely complex. This curse of dimensionality connected to the number of zones is sometimes solved by sampling a number of zones through some auxiliary model (see e.g., \citep{liao13}), or by approximating the log-sums through importance sampling (similar to how \citealt{Bradley10} does in a nested framework). We want to avoid such approximations if possible. However, if the zones would be refined or increase for other reasons, we would likely have to resolve to some sort of sampling. \citet{Rust97} shows how randomization can be used to approximate $\eutil$ in dynamic discrete choice models, and it would be one possible way to decrease computation time.

\subsection{Data}
\input{text/caseStudy/Data.tex}

\subsection{Computation details}
\input{text/caseStudy/compTime.tex}

\subsection{Estimation results}
\input{text/caseStudy/EstResult.tex}

\subsection{Simulation result}
\input{text/caseStudy/Simulation.tex}


