\subsection{Estimation with uncertain travel times}

\subsection{Equivalence between choice of policy and choice of travel pattern}
We will make two additional restrictions that give a more tractable specification. We will, secondly, assume that all uncertainty in the state transitions is captured by $\epsilon_k$. This means that, e.g., travel time uncertainty is cannot be taken into account by individuals. Being able to explicitly model travel time uncertainty would definitely be of great value, and we will attempt to overcome this restriction in future work. 


With these two additional restrictions (and $\epsilon_k \sim G(-\gamma,1)$), the expected value of the value function (the \emph{expected value function}) becomes:%XXXX CHECK THIS!!!
\begin{equation} \label{eq:EV}
\begin{aligned}
\eutil(x_k) &= \int V(s_{k+1})p(ds_{k+1}|s_k,a_k) \\&= \log\left(\sum_{a\in A(x_k)}e^{u(x_k,a) + \eutil(x_{k+1})}\right)
\end{aligned}
\end{equation}
and the probability that an alternative $a$ is choosen when in state $x$ is given by the well-known MNL-formula:
\begin{align}
P(a_k|x_k) &= \frac{e^{u(a_k,x_k) + \eutil(x_{k+1})} }{\sum\limits_{a_k'\in A(x_k)} e^{u(a_k',x_k) + \eutil(x_{k+1}')}} \label{eq:MNL} \\
&=e^{u(a_k,x_k) + \eutil(x_{k+1})- \eutil(x_k)}\label{eq:MNLv2}
\end{align}
where \refeq{eq:EV} together with \refeq{eq:MNL} gives \refeq{eq:MNLv2}.

\subsection{Estimation for recursive logit specification}

Consider an individual $n$ who has been observed to choose a day-path starting from state $x_0$ consisting of a sequence of decisions  $\ve{a} = (a_0,...,a_{T-1})$ and thus traversing the states $\ve{x} = (x_1,...,x_{T})$. The likelihood for this sequence of decisions is, according to \eqref{eq:MNLv2} given by:
 \begin{equation}\label{eq:pPath0}
 \begin{aligned}
 P(\ve{a}|x_0) & = \prod_{i=0}^{T}P(a_i|x_i) \\
 & = \prod_{i=0}^{T} e^{u(a_i,x_i) + \eutil(x_{i+1})-\eutil(x_i)}
 \end{aligned}
 \end{equation}
The standard method for estimating dynamic discrete choice models is the Nested Fixed Point Method (NFXP) \citep{RustML88}. This involves first calculating $\eutil$ and its gradients in each state of the network and then directly use \eqref{eq:pPath0} for estimation. Although possible to apply on the proposed model, the method would be extremely time consuming given the discussion on computation time in Section \ref{seq:computationTime}. If estimation would rely on calculating the value function and gradient of the value function in each state in each iteration, the computation time would likely be $0.4\cdot N_{\text{variables}} \cdot t$ per observation per iteration (as the gradient must be calculated for each variable, requiring at least the additional sum of the gradient of $u + EV$ for each variable). With $10\units{s/observation}$ to calculate $\eutil$, $70$ variables, $3\zdel 300$ observations and $100$ iterations before convergence, this would require $10 \cdot 0.4 \cdot  70 \cdot 3\zdel 300 \cdot 100 \units{s} \approx 1\zdel 000 \units{days}$ to estimate using a single core. 

Methods used to speed up estimation of dynamic discrete choice models, e.g., the method proposed in \citet{aguirregabiria2002swapping}, reduces the burden of value iterations when calculating the value function. As no iteration is needed to evaluate the value function in this model, this would likely not help. Some approximative method is therefore needed.

Each individual is considering all possible locations for each new action. Locations are therefore both state variables and alternative actions so the computation time increases quadratically with the number of locations. Restricting the choice set of locations for individuals is therefore extremely tempting, but combining an activity scheduling model with a location choice set model in a consistent way seems extremely complex. This curse of dimensionality connected to the number of zones is sometimes solved by sampling a number of zones through some auxiliary model (see e.g., \citep{liao13}), or by approximating the log-sums through importance sampling (similar to how \citealt{Bradley10} does in a nested framework). We want to avoid such approximations if possible. However, if the zones would be refined or increase for other reasons, we would likely have to resolve to some sort of sampling. \citet{Rust97} shows how randomization can be used to approximate $\eutil$ in dynamic discrete choice models, and it would be one possible way to decrease computation time.

\subsection{Sampling of alternatives}
In the context of route choice modeling, \citet{fosgerau2013} showed that an MNL over routes in a directed network can be expressed by \eqref{eq:MNLv2} and estimated using the NFXP. From \eqref{eq:pPath0}, observe that: 
\begin{equation}\label{eq:pPath}
\begin{aligned}
P(\ve{a}|x_0) & = \prod_{i=0}^{T} e^{u(a_i,x_i) + \eutil(x_{i+1})-\eutil(x_i)} \\
& = e^{u(\ve{a},x_0) + \eutil(x_{T+1})-\eutil(x_0)}
\end{aligned}
\end{equation}
where $u(\ve{a},x_0) = \sum_{i=0}^{T-1} u(a_i,x_i)$. Since $\eutil(x_{T})$ and $\eutil(x_0)$ are the same for all alternative action sequences starting in $x_0$, the probability for each alternative is proportional to $e^{u(\ve{a},x_0) }$. If $\Agood(x_0)$ is the set of action sequences that, starting from $x_0$, satisfies all space-time constraints, then:
\begin{equation} \label{eq:MNLpath}
P(\ve{a}|x_0) = \frac{e^{u(\ve{a},x_0)}}{\sum\limits_{\ve{a'} \in \Agood(x_0)}e^{u(\ve{a'},x_0)}}.
\end{equation}
Recursive Logit (RL) models has recently been developed extending the MNL case discussed in \citet{fosgerau2013} to cover Nested Logit \citep{mai2015}, MEV \citep{mai2016method} and Mixed Logit specifications \citep{mai2016decomposition}. They have also been applied in a number of scenarios, e.g., in \cite{zimmermann2017bike}  application to route choice for bikes, possibly with the largest network so far in a RL model. The number of links in these models are between 7\zdel 000-40\zdel 000. The model presented here is thus around $2\zdel 000$ times bigger, so although the models are very similar the estimation techniques used for RL-models are not feasible here. 

Here, the equivalence between a RL-model in \eqref{eq:pPath} and an MNL over routes in \eqref{eq:MNLpath} is utilized to allow estimation using sampling of alternatives. 
It is a general property of MNL models that estimating over a subset of alternatives gives consistent estimates if a correction term is added to the utility function \citep{mcfadden78}. The estimates are, however, not efficient and how the choice sets are constructed will determine the efficiency loss. Since the number of alternatives is immense, is is important to use a smart way of sampling alternatives that somewhat resembles the model in order to obtain good estimates. As it is trivial to simulate alternative once the value function has been evaluated, a choice set can be constructed using the described model with an initial guess of the parameters.

Estimation using sampling of alternatives involves sampling a choice set $\Ccsamp_n \subset \Cc_n$ and estimating using the conditional choice probability $P_n(\ve{a}_n|\Ccsamp_n)$ instead of the $P_n(\ve{a}_n|\Cc_n)$. A maximum likelihood estimation on a choice set $\Ccsamp$ gives consistent estimates if the correction term $\log(\bar{q}_n(\Ccsamp_n|j))$ is added to each alternative and $\bar{q}_n(\Ccsamp_n|j)$ satisfies the positive conditioning property, i.e., that if $j\in \Ccsamp_n$ and $\bar{q}_n(\Ccsamp_n|i)>0$ for some $i$, then $\bar{q}_n(\Ccsamp_n|j)>0$. This holds if $\Ccsamp_n$ is sampled from the universal choice set $\Cc_n$ and all alternatives in $\Cc_n$ have a non-zero probability of being sampled.

Let $N$ observations form the set of observations $\obs_N$. The log-likelihood function for $\obs_N$ based on the conditional likelihoods becomes:
\begin{equation} \label{eq:cond_like}
\bar{\LL}(\obs_N;\theta) = \sum_{n=1}^N \log \Bl \frac{e^{u(\ve{a}_n) + \log(q_n(\Ccsamp_n|j))}}{\sum\limits_{\ve{a}^* \in \Ccsamp_n} e^{u(\ve{a}^*) + q_n(\Ccsamp_n|\ve{a}^*)}}\Bh
\end{equation}
If all alternatives in $\Cc_n$ have equal probability of being sampled to the choice set $\Ccsamp$, the correction term $q_n(\Ccsamp_n|j)$ will also be the same for all alternatives and therefore cancel out from the likelihood function. However, if some other sampling protocol is used the probability must be calculated. The sampling protocol use here is the same that \citet{frejinger09} used to estimate an MNL model over the choice of routes in a traffic network. The sampling protocol consists of drawing $R$ alternatives with replacement from the choice set $\Cc_n$ consisting of $J_n$ alternatives, and then adding the observed choice to the choice set. The outcome of such a protocol is $({k}_{n1},{k}_{n2},\dots,{k}_{nJ})$ where ${k}_{nj}$ is the number of times alternative $j$ appears in the choice set, so that $\sum_{j=1}^J {k}_{nj} = R+1$, since the observed alternative $j$ is added once extra to the choice set. Let $q_n(i)$ denote the probability that alternative $j \in \Cc_n$ is sampled. The correction term can then be derived to: $q_n(\Ccsamp_n|j) = K_{\Ccsamp_n}\frac{k_{nj}}{q_n(j)}$. The constant $K_{\Ccsamp_n}$ will cancel out from the likelihood function to give:
\begin{equation} \label{eq:cond_like_corr}
\bar{\LL}(\obs_N;\theta) = \sum_{n=1}^N \log \Bl \frac{e^{u(\ve{a}_n) + \log(\frac{k_{n\ve{a}_n}}{q_n(\ve{a}_n)})}}{\sum\limits_{\ve{a}^* \in \Cc_n} e^{u(\ve{a}^*) + \log(\frac{k_{n\ve{a}^*_n}}{q_n(\ve{a}^*_n)})}}\Bh
\end{equation}
 
As previously mentioned, a choice set is sampled using \refeq{eq:MNL} with a single set of parameters. They were derived by starting from a simple specification of the model, only involving time and cost parameters, and then manually their values until travel times, mode choices and activity episodes were in line with the observations.

 
